{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d3be2d",
   "metadata": {},
   "source": [
    "# Bayesian Networks in PyMC\n",
    "\n",
    "A **Bayesian Network** (also called *Bayes Net* or *Belief Network*) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG). Each node in the DAG corresponds to a random variable, and edges represent conditional dependencies.\n",
    "\n",
    "## Key Ideas\n",
    "\n",
    "1. **Directed Acyclic Graph (DAG)**  \n",
    "   Each variable is a node. Edges indicate direct dependencies. There are no directed cycles.\n",
    "\n",
    "2. **Conditional Probability Distributions (CPDs)**  \n",
    "   Each node has a conditional distribution \\(P(X \\mid \\text{parents}(X))\\).\n",
    "\n",
    "3. **Chain Rule for Bayesian Networks**  \n",
    "   The joint probability factorizes as  \n",
    "   \\[\n",
    "   P(X_1, X_2, \\ldots, X_n) \\;=\\; \\prod_{i=1}^{n} P(X_i \\,\\mid\\, \\text{parents}(X_i))\n",
    "   \\]\n",
    "\n",
    "4. **Inference**  \n",
    "   Inference involves computing the posterior distribution of a set of variables given evidence (observations). Exact inference can be done via message passing in small networks, but for more complex networks, sampling-based (Monte Carlo) methods or variational methods are often used.\n",
    "\n",
    "---\n",
    "\n",
    "## Example: “Sprinkler–Rain–Wet Grass”\n",
    "\n",
    "A classic toy Bayesian Network has three random variables:\n",
    "\n",
    "1. **Rain (R)**: Indicates whether it is raining.  \n",
    "2. **Sprinkler (S)**: Indicates whether the garden sprinkler is turned on.  \n",
    "3. **Wet Grass (W)**: Indicates whether the grass is wet.\n",
    "\n",
    "The dependencies are as follows:\n",
    "\n",
    "- The chance of the sprinkler being on depends on whether it’s raining.  \n",
    "- The grass is wet if either it rains or the sprinkler is on (or both).\n",
    "\n",
    "Graphically:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd84b9ad",
   "metadata": {},
   "source": [
    "### Step 1: Define the CPDs\n",
    "\n",
    "Let’s define each node’s conditional probability distribution (CPD) as follows:\n",
    "\n",
    "1. **P(Rain)**  \n",
    "   \\[\n",
    "   P(R = \\text{true}) = 0.2, \\quad P(R = \\text{false}) = 0.8.\n",
    "   \\]\n",
    "\n",
    "2. **P(Sprinkler | Rain)**  \n",
    "   - If it is raining:  \n",
    "     \\[\n",
    "       P(S = \\text{true} \\mid R = \\text{true}) = 0.1\n",
    "     \\]  \n",
    "   - If it is not raining:  \n",
    "     \\[\n",
    "       P(S = \\text{true} \\mid R = \\text{false}) = 0.5\n",
    "     \\]\n",
    "\n",
    "3. **P(Wet Grass | Rain, Sprinkler)**  \n",
    "   - For simplicity:  \n",
    "     \\[\n",
    "       P(W = \\text{true} \\mid R = \\text{true}, S = \\text{true}) = 0.99\n",
    "     \\]\n",
    "     \\[\n",
    "       P(W = \\text{true} \\mid R = \\text{true}, S = \\text{false}) = 0.9\n",
    "     \\]\n",
    "     \\[\n",
    "       P(W = \\text{true} \\mid R = \\text{false}, S = \\text{true}) = 0.8\n",
    "     \\]\n",
    "     \\[\n",
    "       P(W = \\text{true} \\mid R = \\text{false}, S = \\text{false}) = 0.0\n",
    "     \\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82f51a",
   "metadata": {},
   "source": [
    "## Step 2: Implementing in PyMC\n",
    "\n",
    "We'll use [PyMC](https://github.com/pymc-devs/pymc), a Python library for probabilistic programming, to represent and sample from this Bayesian network. PyMC can handle discrete and continuous variables, as well as more complex models.\n",
    "\n",
    "### Example Code\n",
    "\n",
    "Below is an example of how to define and sample from the \"Sprinkler–Rain–Wet Grass\" network using **PyMC 4+**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d16034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import aesara.tensor as at\n",
    "\n",
    "# Define the model\n",
    "with pm.Model() as model:\n",
    "    # 1. Rain (Bernoulli)\n",
    "    #    P(Rain=True) = 0.2\n",
    "    p_rain = 0.2\n",
    "    rain = pm.Bernoulli(\"rain\", p=p_rain)\n",
    "    \n",
    "    # 2. Sprinkler depends on Rain\n",
    "    #    P(Sprinkler=True | Rain=True)  = 0.1\n",
    "    #    P(Sprinkler=True | Rain=False) = 0.5\n",
    "\n",
    "    def sprinkler_p(r):\n",
    "        return 0.1 * r + 0.5 * (1 - r)\n",
    "    \n",
    "    sprinkler = pm.Bernoulli(\n",
    "        \"sprinkler\",\n",
    "        p=sprinkler_p(rain)\n",
    "    )\n",
    "\n",
    "    # 3. Wet Grass depends on Rain and Sprinkler\n",
    "    #    P(W=true | R=true,  S=true)  = 0.99\n",
    "    #    P(W=true | R=true,  S=false) = 0.90\n",
    "    #    P(W=true | R=false, S=true)  = 0.80\n",
    "    #    P(W=true | R=false, S=false) = 0.00\n",
    "    \n",
    "    # Lookup table for W=true:\n",
    "    w_true_probs = at.as_tensor_variable([\n",
    "        [0.0, 0.8],   # R = false (0), columns: S=false(0), S=true(1)\n",
    "        [0.9, 0.99]   # R = true  (1), columns: S=false(0), S=true(1)\n",
    "    ])\n",
    "    \n",
    "    p_wet_grass = w_true_probs[rain, sprinkler]\n",
    "    wet_grass = pm.Bernoulli(\"wet_grass\", p=p_wet_grass)\n",
    "\n",
    "    # Sampling\n",
    "    trace = pm.sample(draws=2000, tune=1000, chains=2, random_seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc577b2",
   "metadata": {},
   "source": [
    "### Step 3: Inspecting Results\n",
    "\n",
    "After sampling, we can summarize the trace to see the distribution of each variable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d36028",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace, var_names=[\"rain\", \"sprinkler\", \"wet_grass\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27e7e3",
   "metadata": {},
   "source": [
    "This will give you statistics (mean, standard deviation, highest posterior density intervals, etc.) for each random variable, based on the sampled chain.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- We have defined three Bernoulli variables: **Rain**, **Sprinkler**, and **Wet Grass**.\n",
    "- We used a simple table or function to encode the conditional probabilities.\n",
    "- PyMC’s sampling (`pm.sample()`) method generates samples from the joint (if unobserved) or posterior (if some variables are observed).\n",
    "- From the resulting trace, you can estimate quantities like:\n",
    "  \\[\n",
    "    P(\\text{rain} = \\text{true} \\mid \\text{wet_grass} = \\text{true})\n",
    "  \\]\n",
    "  by filtering the samples where `wet_grass=True` and checking the proportion of those samples for which `rain=True`.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- A **Bayesian Network** models how variables depend on each other via conditional probabilities in a DAG.  \n",
    "- **PyMC** can represent and sample from both discrete and continuous Bayesian networks.  \n",
    "- This notebook demonstrates a small discrete Bayesian network (“Sprinkler–Rain–Wet Grass”) and how to perform sampling-based inference in PyMC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae327d",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
